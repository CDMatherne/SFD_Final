"""
Standalone script to save sequences to cache after generation.
This can be called manually after prepare_training_sequences completes.

Usage:
    python save_sequences_cache.py --sequences-file sequences.pkl --data-file data.parquet --start-date 2024-01-01 --end-date 2024-01-07

Or import and use programmatically:
    from ml_course_prediction.training.data_loader import CoursePredictionDataLoader
    loader.save_sequences_to_cache(sequences, df, ...)
"""
import argparse
import logging
import pickle
import pandas as pd
from pathlib import Path
import sys

# Add parent directory to path (same as train.py)
# This allows importing from ml_course_prediction package
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from ml_course_prediction.training.data_loader import CoursePredictionDataLoader

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description='Save training sequences to cache')
    
    parser.add_argument(
        '--sequences-file',
        type=str,
        required=True,
        help='Path to pickle file containing sequences (generated by prepare_training_sequences)'
    )
    parser.add_argument(
        '--data-file',
        type=str,
        required=True,
        help='Path to parquet file containing the original DataFrame used to generate sequences'
    )
    parser.add_argument(
        '--start-date',
        type=str,
        help='Start date for cache key (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--end-date',
        type=str,
        help='End date for cache key (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--vessel-types',
        type=str,
        help='Vessel types used (e.g., "70-89" or "70,71,72")'
    )
    parser.add_argument(
        '--filter-unknown-vessel-types',
        action='store_true',
        help='Whether unknown vessel types were filtered'
    )
    parser.add_argument(
        '--sequence-length',
        type=int,
        default=24,
        help='Sequence length in hours (default: 24)'
    )
    parser.add_argument(
        '--prediction-horizon',
        type=int,
        default=48,
        help='Prediction horizon in hours (default: 48)'
    )
    parser.add_argument(
        '--max-gap-hours',
        type=float,
        default=6.0,
        help='Maximum gap hours for trajectory segmentation (default: 6.0)'
    )
    parser.add_argument(
        '--historical-data-path',
        type=str,
        default=r'C:\AIS_Data_Testing\Historical\2024',
        help='Path to historical data directory (for cache location)'
    )
    
    args = parser.parse_args()
    
    # Load sequences
    logger.info(f"Loading sequences from: {args.sequences_file}")
    try:
        with open(args.sequences_file, 'rb') as f:
            sequences = pickle.load(f)
        logger.info(f"Loaded {len(sequences):,} sequences")
    except Exception as e:
        logger.error(f"Error loading sequences: {e}")
        return 1
    
    # Load original DataFrame
    logger.info(f"Loading original data from: {args.data_file}")
    try:
        df = pd.read_parquet(args.data_file)
        logger.info(f"Loaded {len(df):,} records from DataFrame")
    except Exception as e:
        logger.error(f"Error loading DataFrame: {e}")
        return 1
    
    # Parse vessel types
    vessel_types = None
    if args.vessel_types:
        try:
            if '-' in args.vessel_types:
                start, end = map(int, args.vessel_types.split('-'))
                vessel_types = list(range(start, end + 1))
            else:
                import re
                type_strs = re.split(r'[,\s]+', args.vessel_types.strip())
                vessel_types = [int(t) for t in type_strs if t]
            if vessel_types:
                logger.info(f"Vessel types: {vessel_types}")
        except (ValueError, Exception) as e:
            logger.error(f"Error parsing vessel types '{args.vessel_types}': {e}")
            logger.error("Expected format: '70-89' for range or '70,71,72' for list")
            return 1
    
    # Create data loader (needed for cache saving)
    logger.info("Initializing data loader...")
    loader = CoursePredictionDataLoader(
        historical_data_path=args.historical_data_path,
        sequence_length=args.sequence_length,
        prediction_horizon=args.prediction_horizon,
        max_gap_hours=args.max_gap_hours
    )
    
    # Save sequences to cache
    logger.info("\nSaving sequences to cache...")
    success = loader.save_sequences_to_cache(
        sequences=sequences,
        df=df,
        start_date=args.start_date,
        end_date=args.end_date,
        vessel_types=vessel_types,
        filter_unknown_vessel_types=args.filter_unknown_vessel_types
    )
    
    if success:
        logger.info("\n[OK] Sequences saved to cache successfully!")
        logger.info("Future runs with the same parameters will load from cache automatically.")
        return 0
    else:
        logger.error("\n[FAIL] Failed to save sequences to cache")
        return 1


if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)

